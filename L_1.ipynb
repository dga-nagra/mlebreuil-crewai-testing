{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae53a09-c04c-4916-a146-00e0bb188954",
   "metadata": {},
   "source": [
    "# L1: Automated Project: Planning, Estimation, and Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4058e8-a52c-4365-ac27-da08b67d7fb8",
   "metadata": {},
   "source": [
    "This notebook initial imports will load environment variable fro the .env file located at the root.  \n",
    "Specifically, it will load model api keys.\n",
    "Here we use a local model. No API KEY required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ada5b1-06ec-41e8-8f60-5e0e0d389ffb",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193708e-9802-4161-844a-735f6361e24d",
   "metadata": {
    "height": 199
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama/llama3.2 http://localhost:11430\n",
      "<crewai.llm.LLM object at 0x7facc835bb10> http://localhost:11430 ollama/llama3.2\n"
     ]
    }
   ],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "# from helper import load_env\n",
    "# load_env()\n",
    "from helpers import DEFAULT_LLM\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "print(DEFAULT_LLM.base_url, DEFAULT_LLM.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4e50f",
   "metadata": {},
   "source": [
    "In our case we use a [local model](https://docs.crewai.com/how-to/llm-connections#using-local-models-with-ollama).  \n",
    "Download [Ollama](https://ollama.com/download).  \n",
    "Pull the [desired model](https://github.com/ollama/ollama?tab=readme-ov-file) :\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2\n",
    "```\n",
    "configure the agent:  \n",
    "\n",
    "```python\n",
    "    agent = Agent(\n",
    "        role='Local AI Expert',\n",
    "        goal='Process information using a local model',\n",
    "        backstory=\"An AI assistant running on local hardware.\",\n",
    "        llm=LLM(model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\")\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930b575-a2d5-467b-878f-de78e10b6ba5",
   "metadata": {},
   "source": [
    "## Set OpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cb8100-3058-4cdc-969b-c64a46a408e4",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "# os.environ['OPENAI_MODEL_NAME'] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b83836-9ccb-47d7-a97b-9a68aebfaa42",
   "metadata": {},
   "source": [
    "## Loading Tasks and Agents YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4e362d-c010-43dd-88c4-e7db87834fb4",
   "metadata": {
    "height": 283
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config_type, file_path \u001b[38;5;129;01min\u001b[39;00m files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 11\u001b[0m         configs[config_type] \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Assign loaded configurations to specific variables\u001b[39;00m\n\u001b[1;32m     14\u001b[0m agents_config \u001b[38;5;241m=\u001b[39m configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magents\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'agents': 'config_L1/agents.yaml',\n",
    "    'tasks': 'config_L1/tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "agents_config = configs['agents']\n",
    "tasks_config = configs['tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f50c89-a326-4e4c-93a1-79be3fcda14b",
   "metadata": {},
   "source": [
    "## Create Pydantic Models for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8626d2-e48a-4b7e-a061-a8eb492c9036",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TaskEstimate(BaseModel):\n",
    "    task_name: str = Field(..., description=\"Name of the task\")\n",
    "    estimated_time_hours: float = Field(..., description=\"Estimated time to complete the task in hours\")\n",
    "    required_resources: List[str] = Field(..., description=\"List of resources required to complete the task\")\n",
    "\n",
    "class Milestone(BaseModel):\n",
    "    milestone_name: str = Field(..., description=\"Name of the milestone\")\n",
    "    tasks: List[str] = Field(..., description=\"List of task IDs associated with this milestone\")\n",
    "\n",
    "class ProjectPlan(BaseModel):\n",
    "    tasks: List[TaskEstimate] = Field(..., description=\"List of tasks with their estimates\")\n",
    "    milestones: List[Milestone] = Field(..., description=\"List of project milestones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6524c-48e7-460e-8345-3b7a872b714a",
   "metadata": {},
   "source": [
    "## Create Crew, Agents and Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655927f-c10c-4c06-852a-d9c96fdfbfb9",
   "metadata": {
    "height": 776
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span batch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 741, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 1075, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 1346, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 741, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 1075, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/usr/lib/python3.11/ssl.py\", line 1346, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n",
      "    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/debian/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    }
   ],
   "source": [
    "# default_llm = LLM(model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\")\n",
    "default_llm = DEFAULT_LLM  # LLM(model=\"ollama/llama3.2\")\n",
    "\n",
    "# Creating Agents\n",
    "project_planning_agent = Agent(\n",
    "  config=agents_config['project_planning_agent'],\n",
    "  llm=default_llm,\n",
    ")\n",
    "\n",
    "estimation_agent = Agent(\n",
    "  config=agents_config['estimation_agent'],\n",
    "  llm=default_llm,\n",
    ")\n",
    "\n",
    "resource_allocation_agent = Agent(\n",
    "  config=agents_config['resource_allocation_agent'],\n",
    "  llm=default_llm,\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "task_breakdown = Task(\n",
    "  config=tasks_config['task_breakdown'],\n",
    "  agent=project_planning_agent,\n",
    ")\n",
    "\n",
    "time_resource_estimation = Task(\n",
    "  config=tasks_config['time_resource_estimation'],\n",
    "  agent=estimation_agent\n",
    ")\n",
    "\n",
    "resource_allocation = Task(\n",
    "  config=tasks_config['resource_allocation'],\n",
    "  agent=resource_allocation_agent,\n",
    "  output_pydantic=ProjectPlan # This is the structured output we want\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "crew = Crew(\n",
    "  agents=[\n",
    "    project_planning_agent,\n",
    "    estimation_agent,\n",
    "    resource_allocation_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    task_breakdown,\n",
    "    time_resource_estimation,\n",
    "    resource_allocation\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b901cf-3630-4662-81a7-762da6773d3b",
   "metadata": {},
   "source": [
    "## Crew's Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e861574-0f9b-4f2c-b2d1-a230fc3a53a3",
   "metadata": {
    "height": 708
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Project Type:** Website\n",
       "\n",
       "**Project Objectives:** Create a website for a small business\n",
       "\n",
       "**Industry:** Technology\n",
       "\n",
       "**Team Members:**\n",
       "\n",
       "- John Doe (Project Manager)\n",
       "- Jane Doe (Software Engineer)\n",
       "- Bob Smith (Designer)\n",
       "- Alice Johnson (QA Engineer)\n",
       "- Tom Brown (QA Engineer)\n",
       "\n",
       "**Project Requirements:**\n",
       "\n",
       "- Create a responsive design that works well on desktop and mobile devices\n",
       "- Implement a modern, visually appealing user interface with a clean look\n",
       "- Develop a user-friendly navigation system with intuitive menu structure\n",
       "- Include an \"About Us\" page highlighting the company's history and values\n",
       "- Design a \"Services\" page showcasing the business's offerings with descriptions\n",
       "- Create a \"Contact Us\" page with a form and integrated map for communication\n",
       "- Implement a blog section for sharing industry news and company updates\n",
       "- Ensure fast loading times and optimize for search engines (SEO)\n",
       "- Integrate social media links and sharing capabilities\n",
       "- Include a testimonials section to showcase customer feedback and build trust\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "project = 'Website'\n",
    "industry = 'Technology'\n",
    "project_objectives = 'Create a website for a small business'\n",
    "team_members = \"\"\"\n",
    "- John Doe (Project Manager)\n",
    "- Jane Doe (Software Engineer)\n",
    "- Bob Smith (Designer)\n",
    "- Alice Johnson (QA Engineer)\n",
    "- Tom Brown (QA Engineer)\n",
    "\"\"\"\n",
    "project_requirements = \"\"\"\n",
    "- Create a responsive design that works well on desktop and mobile devices\n",
    "- Implement a modern, visually appealing user interface with a clean look\n",
    "- Develop a user-friendly navigation system with intuitive menu structure\n",
    "- Include an \"About Us\" page highlighting the company's history and values\n",
    "- Design a \"Services\" page showcasing the business's offerings with descriptions\n",
    "- Create a \"Contact Us\" page with a form and integrated map for communication\n",
    "- Implement a blog section for sharing industry news and company updates\n",
    "- Ensure fast loading times and optimize for search engines (SEO)\n",
    "- Integrate social media links and sharing capabilities\n",
    "- Include a testimonials section to showcase customer feedback and build trust\n",
    "\"\"\"\n",
    "\n",
    "# Format the dictionary as Markdown for a better display in Jupyter Lab\n",
    "formatted_output = f\"\"\"\n",
    "**Project Type:** {project}\n",
    "\n",
    "**Project Objectives:** {project_objectives}\n",
    "\n",
    "**Industry:** {industry}\n",
    "\n",
    "**Team Members:**\n",
    "{team_members}\n",
    "**Project Requirements:**\n",
    "{project_requirements}\n",
    "\"\"\"\n",
    "# Display the formatted output as Markdown\n",
    "display(Markdown(formatted_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15198e13-e9ec-44d8-b15e-c97b7b7320bb",
   "metadata": {},
   "source": [
    "## Kicking off the crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40b53e-0a49-4198-a263-c79a6a3af603",
   "metadata": {
    "height": 233
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:Failed to get supported params: argument of type 'NoneType' is not iterable\n",
      "ERROR:root:LiteLLM call failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=deepseek-r1:70b\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mThe Ultimate Project Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCarefully analyze the project_requirements for the Website project and break them down into individual tasks. Define each task's scope in detail, set achievable timelines, and ensure that all dependencies are accounted for:\n",
      "\n",
      "- Create a responsive design that works well on desktop and mobile devices\n",
      "- Implement a modern, visually appealing user interface with a clean look\n",
      "- Develop a user-friendly navigation system with intuitive menu structure\n",
      "- Include an \"About Us\" page highlighting the company's history and values\n",
      "- Design a \"Services\" page showcasing the business's offerings with descriptions\n",
      "- Create a \"Contact Us\" page with a form and integrated map for communication\n",
      "- Implement a blog section for sharing industry news and company updates\n",
      "- Ensure fast loading times and optimize for search engines (SEO)\n",
      "- Integrate social media links and sharing capabilities\n",
      "- Include a testimonials section to showcase customer feedback and build trust\n",
      "\n",
      "\n",
      "Team members:\n",
      "\n",
      "- John Doe (Project Manager)\n",
      "- Jane Doe (Software Engineer)\n",
      "- Bob Smith (Designer)\n",
      "- Alice Johnson (QA Engineer)\n",
      "- Tom Brown (QA Engineer)\n",
      "\n",
      "\u001b[00m\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\u001b[91m Error during LLM call: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=deepseek-r1:70b\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[00m\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=deepseek-r1:70b\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_type\u001b[39m\u001b[38;5;124m'\u001b[39m: project,\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_objectives\u001b[39m\u001b[38;5;124m'\u001b[39m: project_objectives,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_requirements\u001b[39m\u001b[38;5;124m'\u001b[39m: project_requirements\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Run the crew\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/crew.py:558\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    555\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 558\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    560\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/crew.py:665\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/crew.py:767\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    764\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    766\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 767\u001b[0m task_output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [task_output]\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/task.py:302\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    297\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/task.py:366\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    362\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[0;32m--> 366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    373\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    374\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    375\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    382\u001b[0m )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agent.py:259\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agent.py:248\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    245\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_trained_data(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mask_for_human_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:112\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_unknown_error(e)\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:102\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    105\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:160\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_context_length_exceeded(e):\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_context_length()\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:140\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_rpm_limit()\n\u001b[0;32m--> 140\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_llm_response(answer)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:210\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    207\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    214\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:201\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    207\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/crewai/llm.py:252\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    249\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# --- 2) Make the completion call\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m response_message \u001b[38;5;241m=\u001b[39m cast(Choices, cast(ModelResponse, response)\u001b[38;5;241m.\u001b[39mchoices)[\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    255\u001b[0m ]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    256\u001b[0m text_response \u001b[38;5;241m=\u001b[39m response_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/utils.py:1100\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1097\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1098\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1099\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/utils.py:978\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/main.py:2981\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2980\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 2981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   2982\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   2983\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   2984\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   2985\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2986\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   2987\u001b[0m     )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/main.py:943\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     model \u001b[38;5;241m=\u001b[39m deployment_id\n\u001b[1;32m    942\u001b[0m     custom_llm_provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 943\u001b[0m model, custom_llm_provider, dynamic_api_key, api_base \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm_provider\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    951\u001b[0m     provider_specific_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m provider_specific_header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_llm_provider\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m custom_llm_provider\n\u001b[1;32m    953\u001b[0m ):\n\u001b[1;32m    954\u001b[0m     headers\u001b[38;5;241m.\u001b[39mupdate(provider_specific_header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py:356\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBadRequestError):\n\u001b[0;32m--> 356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         error_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetLLMProvider Exception - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124moriginal model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m         )\n",
      "File \u001b[0;32m~/demo/mlebreuil-crewai-testing/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py:333\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    331\u001b[0m     error_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Pass model as E.g. For \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuggingface\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m inference endpoints pass in `completion(model=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuggingface/starcoder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# maps to openai.NotFoundError, this is raised when openai does not recognize the llm\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBadRequestError(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         message\u001b[38;5;241m=\u001b[39merror_str,\n\u001b[1;32m    335\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    336\u001b[0m         response\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mResponse(\n\u001b[1;32m    337\u001b[0m             status_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m    338\u001b[0m             content\u001b[38;5;241m=\u001b[39merror_str,\n\u001b[1;32m    339\u001b[0m             request\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mRequest(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/BerriAI/litellm\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         ),\n\u001b[1;32m    341\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_base, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi base needs to be a string. api_base=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(api_base)\n\u001b[1;32m    346\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=deepseek-r1:70b\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
     ]
    }
   ],
   "source": [
    "# The given Python dictionary\n",
    "inputs = {\n",
    "  'project_type': project,\n",
    "  'project_objectives': project_objectives,\n",
    "  'industry': industry,\n",
    "  'team_members': team_members,\n",
    "  'project_requirements': project_requirements\n",
    "}\n",
    "\n",
    "# Run the crew\n",
    "result = crew.kickoff(\n",
    "  inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879258f-52df-4503-b08e-acd516d0a946",
   "metadata": {},
   "source": [
    "## Usage Metrics and Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94dad33-91c9-4aac-8e16-24117dbbef46",
   "metadata": {},
   "source": [
    "Lets see how much it would cost each time if this crew runs at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3b165-2a4b-46cc-93f7-696dffff1e10",
   "metadata": {
    "height": 164
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total costs: $0.0009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>cached_prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>successful_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6263</td>\n",
       "      <td>3537</td>\n",
       "      <td>0</td>\n",
       "      <td>2726</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_tokens  prompt_tokens  cached_prompt_tokens  completion_tokens  \\\n",
       "0          6263           3537                     0               2726   \n",
       "\n",
       "   successful_requests  \n",
       "0                    3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "costs = 0.150 * (crew.usage_metrics.prompt_tokens + crew.usage_metrics.completion_tokens) / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([crew.usage_metrics.dict()])\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982e83a-9e54-4510-9f06-751b34848287",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396b0f6-e3ae-4a89-a3e9-ca53aa042c40",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': [{'task_name': 'Responsive Design',\n",
       "   'estimated_time_hours': 40.0,\n",
       "   'required_resources': ['2 developers', '1 designer']},\n",
       "  {'task_name': 'Modern User Interface',\n",
       "   'estimated_time_hours': 80.0,\n",
       "   'required_resources': ['3 developers', '1 designer']},\n",
       "  {'task_name': 'Navigation System',\n",
       "   'estimated_time_hours': 30.0,\n",
       "   'required_resources': ['2 developers', '1 QA Engineer']},\n",
       "  {'task_name': 'About Us Page',\n",
       "   'estimated_time_hours': 20.0,\n",
       "   'required_resources': ['1 developer', '1 writer']},\n",
       "  {'task_name': 'Services Page',\n",
       "   'estimated_time_hours': 30.0,\n",
       "   'required_resources': ['2 developers', '1 writer']},\n",
       "  {'task_name': 'Contact Us Page',\n",
       "   'estimated_time_hours': 30.0,\n",
       "   'required_resources': ['2 developers', '1 writer']},\n",
       "  {'task_name': 'Blog Section',\n",
       "   'estimated_time_hours': 60.0,\n",
       "   'required_resources': ['3 developers', '1 writer']},\n",
       "  {'task_name': 'SEO Optimization',\n",
       "   'estimated_time_hours': 40.0,\n",
       "   'required_resources': ['2 developers', '1 SEO Specialist']},\n",
       "  {'task_name': 'Social Media Integration',\n",
       "   'estimated_time_hours': 20.0,\n",
       "   'required_resources': ['1 developer', '1 social media Specialist']},\n",
       "  {'task_name': 'Testimonials Section',\n",
       "   'estimated_time_hours': 30.0,\n",
       "   'required_resources': ['2 developers', '1 writer']}],\n",
       " 'milestones': [{'milestone_name': 'Responsive Design Completion',\n",
       "   'tasks': ['Responsive Design']},\n",
       "  {'milestone_name': 'Modern User Interface Completion',\n",
       "   'tasks': ['Modern User Interface']},\n",
       "  {'milestone_name': 'Navigation System Completion',\n",
       "   'tasks': ['Navigation System']},\n",
       "  {'milestone_name': 'SEO Optimization Completion',\n",
       "   'tasks': ['SEO Optimization']}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pydantic.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffcc83-350e-4f99-b03b-458690cc0ed2",
   "metadata": {},
   "source": [
    "## Inspect further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bbf90-4bfc-4529-84dd-d0bd00198353",
   "metadata": {
    "height": 147
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4c8c th {\n",
       "  font-size: 120%;\n",
       "}\n",
       "#T_d4c8c  td {\n",
       "  font-size: 120%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4c8c\" border=\"1\">\n",
       "  <caption>Task Details</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4c8c_level0_col0\" class=\"col_heading level0 col0\" >task_name</th>\n",
       "      <th id=\"T_d4c8c_level0_col1\" class=\"col_heading level0 col1\" >estimated_time_hours</th>\n",
       "      <th id=\"T_d4c8c_level0_col2\" class=\"col_heading level0 col2\" >required_resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4c8c_row0_col0\" class=\"data row0 col0\" >Responsive Design</td>\n",
       "      <td id=\"T_d4c8c_row0_col1\" class=\"data row0 col1\" >40.000000</td>\n",
       "      <td id=\"T_d4c8c_row0_col2\" class=\"data row0 col2\" >['2 developers', '1 designer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4c8c_row1_col0\" class=\"data row1 col0\" >Modern User Interface</td>\n",
       "      <td id=\"T_d4c8c_row1_col1\" class=\"data row1 col1\" >80.000000</td>\n",
       "      <td id=\"T_d4c8c_row1_col2\" class=\"data row1 col2\" >['3 developers', '1 designer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4c8c_row2_col0\" class=\"data row2 col0\" >Navigation System</td>\n",
       "      <td id=\"T_d4c8c_row2_col1\" class=\"data row2 col1\" >30.000000</td>\n",
       "      <td id=\"T_d4c8c_row2_col2\" class=\"data row2 col2\" >['2 developers', '1 QA Engineer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4c8c_row3_col0\" class=\"data row3 col0\" >About Us Page</td>\n",
       "      <td id=\"T_d4c8c_row3_col1\" class=\"data row3 col1\" >20.000000</td>\n",
       "      <td id=\"T_d4c8c_row3_col2\" class=\"data row3 col2\" >['1 developer', '1 writer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4c8c_row4_col0\" class=\"data row4 col0\" >Services Page</td>\n",
       "      <td id=\"T_d4c8c_row4_col1\" class=\"data row4 col1\" >30.000000</td>\n",
       "      <td id=\"T_d4c8c_row4_col2\" class=\"data row4 col2\" >['2 developers', '1 writer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d4c8c_row5_col0\" class=\"data row5 col0\" >Contact Us Page</td>\n",
       "      <td id=\"T_d4c8c_row5_col1\" class=\"data row5 col1\" >30.000000</td>\n",
       "      <td id=\"T_d4c8c_row5_col2\" class=\"data row5 col2\" >['2 developers', '1 writer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d4c8c_row6_col0\" class=\"data row6 col0\" >Blog Section</td>\n",
       "      <td id=\"T_d4c8c_row6_col1\" class=\"data row6 col1\" >60.000000</td>\n",
       "      <td id=\"T_d4c8c_row6_col2\" class=\"data row6 col2\" >['3 developers', '1 writer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d4c8c_row7_col0\" class=\"data row7 col0\" >SEO Optimization</td>\n",
       "      <td id=\"T_d4c8c_row7_col1\" class=\"data row7 col1\" >40.000000</td>\n",
       "      <td id=\"T_d4c8c_row7_col2\" class=\"data row7 col2\" >['2 developers', '1 SEO Specialist']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d4c8c_row8_col0\" class=\"data row8 col0\" >Social Media Integration</td>\n",
       "      <td id=\"T_d4c8c_row8_col1\" class=\"data row8 col1\" >20.000000</td>\n",
       "      <td id=\"T_d4c8c_row8_col2\" class=\"data row8 col2\" >['1 developer', '1 social media Specialist']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4c8c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d4c8c_row9_col0\" class=\"data row9 col0\" >Testimonials Section</td>\n",
       "      <td id=\"T_d4c8c_row9_col1\" class=\"data row9 col1\" >30.000000</td>\n",
       "      <td id=\"T_d4c8c_row9_col2\" class=\"data row9 col2\" >['2 developers', '1 writer']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6719e486d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = result.pydantic.dict()['tasks']\n",
    "df_tasks = pd.DataFrame(tasks)\n",
    "\n",
    "# Display the DataFrame as an HTML table\n",
    "df_tasks.style.set_table_attributes('border=\"1\"').set_caption(\"Task Details\").set_table_styles(\n",
    "    [{'selector': 'th, td', 'props': [('font-size', '120%')]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210cae8-e028-4f7e-90ed-950ef86d41e5",
   "metadata": {},
   "source": [
    "### Inspecting Milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2f18c-2d5b-41a9-837b-265e7aa245d0",
   "metadata": {
    "height": 147
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c1b50 th {\n",
       "  font-size: 120%;\n",
       "}\n",
       "#T_c1b50  td {\n",
       "  font-size: 120%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c1b50\" border=\"1\">\n",
       "  <caption>Task Details</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1b50_level0_col0\" class=\"col_heading level0 col0\" >milestone_name</th>\n",
       "      <th id=\"T_c1b50_level0_col1\" class=\"col_heading level0 col1\" >tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1b50_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c1b50_row0_col0\" class=\"data row0 col0\" >Responsive Design Completion</td>\n",
       "      <td id=\"T_c1b50_row0_col1\" class=\"data row0 col1\" >['Responsive Design']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1b50_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c1b50_row1_col0\" class=\"data row1 col0\" >Modern User Interface Completion</td>\n",
       "      <td id=\"T_c1b50_row1_col1\" class=\"data row1 col1\" >['Modern User Interface']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1b50_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c1b50_row2_col0\" class=\"data row2 col0\" >Navigation System Completion</td>\n",
       "      <td id=\"T_c1b50_row2_col1\" class=\"data row2 col1\" >['Navigation System']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1b50_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c1b50_row3_col0\" class=\"data row3 col0\" >SEO Optimization Completion</td>\n",
       "      <td id=\"T_c1b50_row3_col1\" class=\"data row3 col1\" >['SEO Optimization']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6738105090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milestones = result.pydantic.dict()['milestones']\n",
    "df_milestones = pd.DataFrame(milestones)\n",
    "\n",
    "# Display the DataFrame as an HTML table\n",
    "df_milestones.style.set_table_attributes('border=\"1\"').set_caption(\"Task Details\").set_table_styles(\n",
    "    [{'selector': 'th, td', 'props': [('font-size', '120%')]}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
